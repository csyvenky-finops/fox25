{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Datasets Notebook\n",
    "\n",
    "This notebook is designed to compare two datasets by analyzing their schema headers. It performs the following tasks:\n",
    "\n",
    "- **Alphabetical Reordering:**  \n",
    "  The columns from each dataset are sorted alphabetically to enable a standardized comparison irrespective of the original column order.\n",
    "\n",
    "- **Difference Identification:**  \n",
    "  Once sorted, any discrepancies between the two headers are highlighted. This includes:\n",
    "  - Columns that exist in one dataset but are missing in the other.\n",
    "  - Differences in column names, which may indicate changes or misalignments in data ingestion and transformation processes.\n",
    "\n",
    "- **Developer Guidance:**  \n",
    "  This comparison helps ensure that any evolutions in the upstream data schema are reflected in our processing pipelines. It is especially useful when:\n",
    "  - Integrating new data sources.\n",
    "  - Updating ETL processes.\n",
    "  - Validating changes between different environments or versions of the data.\n",
    "\n",
    "Please update this notebook as needed when schema changes are detected to maintain data consistency across our reporting systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define file paths\n",
    "azure_filepath = '../data/usage_data_w_tagsv.csv'\n",
    "aws_filepath = '../data/usage_data_aws_workspace_v1.1.csv'\n",
    "\n",
    "# Check if files exist\n",
    "if not os.path.exists(azure_filepath):\n",
    "    raise FileNotFoundError(f\"No such file or directory: '{azure_filepath}'\")\n",
    "if not os.path.exists(aws_filepath):\n",
    "    raise FileNotFoundError(f\"No such file or directory: '{aws_filepath}'\")\n",
    "\n",
    "# Load the CSV files into dataframes with renamed variables\n",
    "df_azure = pd.read_csv(azure_filepath)\n",
    "df_aws = pd.read_csv(aws_filepath)\n",
    "\n",
    "# Extract the column sets for each dataframe\n",
    "columns_azure = set(df_azure.columns)\n",
    "columns_aws = set(df_aws.columns)\n",
    "\n",
    "# Compare columns\n",
    "common_columns = columns_azure.intersection(columns_aws)\n",
    "unique_to_azure = columns_azure - columns_aws\n",
    "unique_to_aws = columns_aws - columns_azure\n",
    "\n",
    "print(\"Common Columns:\")\n",
    "print(common_columns)\n",
    "print(\"\\nColumns unique to usage_data_w_tagsv.csv (Azure):\")\n",
    "print(unique_to_azure)\n",
    "print(\"\\nColumns unique to usage_data_aws_workspace.csv (AWS):\")\n",
    "print(unique_to_aws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aws\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
